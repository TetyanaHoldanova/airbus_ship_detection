{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f103a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train_v2/'\n",
    "TEST_DIR = 'data/test_v2/'\n",
    "SEGMENTATION_DIR = 'data/train_ship_segmentations_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "15a75e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 768\n",
    "W = 768\n",
    "\n",
    "GROUP_SIZE = 2000\n",
    "BATCH_SIZE = 32\n",
    "IMG_SCALING = (3, 3)\n",
    "MAX_TRAIN_STEPS = 100\n",
    "N_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "273c436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "92342d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = os.listdir(TRAIN_DIR)\n",
    "test = os.listdir(TEST_DIR)\n",
    "\n",
    "masks = pd.read_csv(SEGMENTATION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07090433",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6dc44d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    '''\n",
    "    Load, preprocess and split dataset\n",
    "    @return: 2 x pd.DataFrame (n, 2)\n",
    "    '''\n",
    "    # Mark files that contain ship\n",
    "    masks['has_ship'] = masks['EncodedPixels'].map(lambda x: 0 if type(x) == float else 1)\n",
    "    \n",
    "    # Count ships on each image\n",
    "    unique_images = masks.groupby('ImageId').agg(n_ships=('has_ship', 'sum')).reset_index()\n",
    "    masks.drop('has_ship', axis=1, inplace=True)\n",
    "    \n",
    "    # Delete corrupt files with size < 50 kB\n",
    "    unique_images['file_size'] = unique_images['ImageId'].map(lambda x: os.stat(TRAIN_DIR + x).st_size/1024)\n",
    "    unique_images = unique_images[unique_images['file_size'] > 50]\n",
    "    unique_images.drop('file_size', axis=1, inplace=True)\n",
    "    \n",
    "    # Get balanced dataset\n",
    "    balanced_df = unique_images.groupby('n_ships', group_keys=False).apply(lambda x: x.sample(GROUP_SIZE) if len(x) > GROUP_SIZE else x.sample(len(x)))\n",
    "    \n",
    "    # Split the Dataset into the Train and Validation Sets\n",
    "    train_df, val_df = train_test_split(balanced_df, test_size=0.2, stratify=balanced_df['n_ships'])\n",
    "    train_df.drop('n_ships', axis=1, inplace=True)\n",
    "    val_df.drop('n_ships', axis=1, inplace=True)\n",
    "    \n",
    "    # Merge with Masks DataFrame\n",
    "    train_df = pd.merge(masks, train_df)\n",
    "    val_df = pd.merge(masks, val_df)\n",
    "    \n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "train_df, val_df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "bf9e345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>198320 10 199088 10 199856 10 200624 10 201392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>254389 9 255157 17 255925 17 256693 17 257461 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35359</th>\n",
       "      <td>ffed6e788.jpg</td>\n",
       "      <td>158 17 925 20 1693 21 2460 21 3228 21 3995 21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35360</th>\n",
       "      <td>ffee378e9.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35361</th>\n",
       "      <td>ffef7c3f3.jpg</td>\n",
       "      <td>434402 2 435169 5 435937 6 436704 7 437472 6 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35362</th>\n",
       "      <td>ffef7c3f3.jpg</td>\n",
       "      <td>119822 1 120589 3 121356 5 122123 7 122890 9 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35363</th>\n",
       "      <td>ffef7c3f3.jpg</td>\n",
       "      <td>476372 3 477138 5 477906 6 478674 6 479443 5 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35364 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId                                      EncodedPixels\n",
       "0      000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "1      000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...\n",
       "2      000194a2d.jpg  198320 10 199088 10 199856 10 200624 10 201392...\n",
       "3      000194a2d.jpg  55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...\n",
       "4      000194a2d.jpg  254389 9 255157 17 255925 17 256693 17 257461 ...\n",
       "...              ...                                                ...\n",
       "35359  ffed6e788.jpg  158 17 925 20 1693 21 2460 21 3228 21 3995 21 ...\n",
       "35360  ffee378e9.jpg                                                NaN\n",
       "35361  ffef7c3f3.jpg  434402 2 435169 5 435937 6 436704 7 437472 6 4...\n",
       "35362  ffef7c3f3.jpg  119822 1 120589 3 121356 5 122123 7 122890 9 1...\n",
       "35363  ffef7c3f3.jpg  476372 3 477138 5 477906 6 478674 6 479443 5 4...\n",
       "\n",
       "[35364 rows x 2 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7363d82",
   "metadata": {},
   "source": [
    "# Data Generator and Augmentation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a270750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decoder(rle_string):\n",
    "    '''\n",
    "    Convert RLE-encoded values into the mask\n",
    "    @param rle_string: str\n",
    "    @return: np.array with shape (768, 768)\n",
    "    '''    \n",
    "    if pd.isna(rle_string):\n",
    "        return np.zeros((H, W))\n",
    "\n",
    "    rle_string = [int(n) for n in rle_string.split(' ')]\n",
    "    mask = np.zeros(H * W,dtype=np.uint8)\n",
    "    for i in range(0, len(rle_string), 2):\n",
    "        start = rle_string[i] - 1\n",
    "        end = start + rle_string[i+1]\n",
    "        mask[start:end] = 255\n",
    "    mask = mask.reshape(H, W)\n",
    "    mask = mask.T\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e61540e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, df, df_path=TRAIN_DIR, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        self.df = df\n",
    "        self.df_path = df_path\n",
    "        self.batch_size = batch_size \n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        df_datagen = ImageDataGenerator()\n",
    "        param = {'rotation_range': 45, \n",
    "                 'horizontal_flip': True,\n",
    "                 'vertical_flip': True}\n",
    "        X = np.empty((self.batch_size, 256, 256, 3), dtype=np.float32)\n",
    "        y = np.empty((self.batch_size, 256, 256, 1), dtype=np.float32)\n",
    "        \n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        \n",
    "        for i, Id in enumerate(self.df['ImageId'].iloc[indexes]):\n",
    "            img =  np.array(PIL.Image.open(self.df_path + Id))\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            print(img.shape)\n",
    "            X[i,] = df_datagen.apply_transform(x=img, transform_parameters=param)\n",
    "\n",
    "            mask = np.array(rle_decoder(self.df['EncodedPixels'].iloc[i]))\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            print(mask.shape)\n",
    "            y[i,] = df_datagen.apply_transform(x=mask, transform_parameters=param)\n",
    "        \n",
    "        return X / 255.0, y\n",
    "    \n",
    "#ValueError: Input arrays must be multi-channel 2D images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd50d2",
   "metadata": {},
   "source": [
    "# Data Generator and Augmentation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "70e856a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decoder(rle_string):\n",
    "    '''\n",
    "    Convert RLE-encoded values into the mask\n",
    "    @param rle_string: str\n",
    "    @return: np.array with shape (W, H)\n",
    "    '''    \n",
    "    # Return zero matrices if the image does not have ships\n",
    "    if pd.isna(rle_string):\n",
    "        return np.zeros((H, W))\n",
    "    \n",
    "    rle_string = [int(n) for n in rle_string.split(' ')]\n",
    "    mask = np.zeros(H * W, dtype=np.uint8)   # Create a zero matrix as a background\n",
    "    \n",
    "    for i in range(0, len(rle_string), 2):\n",
    "        start = rle_string[i] - 1            # Find the start position\n",
    "        end = start + rle_string[i+1]        # Find the end position\n",
    "        mask[start:end] = 1                  # Fill ship pixels with 1\n",
    "        \n",
    "    return mask.reshape(H, W).T\n",
    "\n",
    "\n",
    "def masks_as_image(rle_list):\n",
    "    '''\n",
    "    Create full mask of the training image\n",
    "    @param rle_list: list of the RLE-encoded masks of each ship in one whole training image\n",
    "    @return: np.ndarray\n",
    "    '''\n",
    "    masks = np.zeros((768, 768), dtype = np.int16)     # Create a zero matrix as a background\n",
    "    \n",
    "    for mask in rle_list:                               \n",
    "        if isinstance(mask, str): \n",
    "            masks += rle_decoder(mask)                 # Use rle_decoder to create mask for whole image\n",
    "    \n",
    "    return np.expand_dims(masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4d0724d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(df, batch_size = BATCH_SIZE, img_scaling = IMG_SCALING):\n",
    "    '''\n",
    "    Make a python generator in order to get batches of training and validation samples\n",
    "    @param df: training or validation dataframe\n",
    "    @param batch_size: number of samples in one iteration\n",
    "    '''\n",
    "    # Group images and collect the corresponding masks\n",
    "    unique_images = list(df.groupby('ImageId'))                       \n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(unique_images)                              # Shuffle the images\n",
    "        \n",
    "        for img_id,  mask_df in unique_images:\n",
    "            img = cv2.imread(TRAIN_DIR + img_id)                      # Read the image file\n",
    "            mask = masks_as_image(mask_df['EncodedPixels'].values)    # Make masks for the each image\n",
    "            \n",
    "            if pd.notna(img_scaling):                                 # Scale images and masks\n",
    "                img = img[::img_scaling[0], ::img_scaling[1]]\n",
    "                mask = mask[::img_scaling[0], ::img_scaling[1]]\n",
    "            \n",
    "            images.append(img) \n",
    "            masks.append(mask)\n",
    "                \n",
    "            # Check if the lenght of the data more that batch size\n",
    "            if len(images) >= batch_size:                              \n",
    "                yield np.array(images) / 255.0, np.array(masks)       # Yield scaled images array and masks array\n",
    "                images, masks = [], []                                # Ð¡lean up images and masks arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1d315abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate traininig data \n",
    "train_gen = data_generator(train_df)\n",
    "val_gen = data_generator(val_df)\n",
    "\n",
    "train_x, train_y = next(train_gen)\n",
    "val_x, val_y = next(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2a60d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "params = {'rotation_range': 45, \n",
    "          'horizontal_flip': True,\n",
    "          'vertical_flip': True,\n",
    "          'data_format': 'channels_last'}\n",
    "\n",
    "image_generator = ImageDataGenerator(**params)\n",
    "masks_generator = ImageDataGenerator(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fb23b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_generator(generator):\n",
    "    '''\n",
    "    Make a python generator in order to get augmented batches ofimages and masks\n",
    "    @param generator: data generator \n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # For generated batches of masks and images\n",
    "    for images, masks in generator:\n",
    "        # Generates batches of augmented images\n",
    "        aug_imgs = image_generator.flow(255 * images,\n",
    "                                        batch_size=len(images),\n",
    "                                        seed=42, \n",
    "                                        shuffle=True)\n",
    "        \n",
    "        # Generates batches of augmented masks\n",
    "        aug_masks = masks_generator.flow(masks,\n",
    "                                        batch_size=len(masks),\n",
    "                                        seed=42,\n",
    "                                        shuffle=True)\n",
    "        \n",
    "        # Yield augmented images and masks \n",
    "        yield next(aug_imgs) / 255.0, next(aug_masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f7d4bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_gen = augmented_generator(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "t_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "78aafe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b09b4",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "259e391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "def build_unet(shape = (256, 256, 3)):\n",
    "    input_layer = layers.Input(shape=shape)\n",
    "    \n",
    "    conv1 = layers.Conv2D(8, (3, 3), activation = 'relu', padding = 'same')(input_layer)\n",
    "    conv1 = layers.Conv2D(8, (3, 3), activation = 'relu', padding = 'same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (pool1)\n",
    "    conv2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2)) (conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (pool2)\n",
    "    conv3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (conv3)\n",
    "    pool3 = layers.MaxPooling2D((2, 2)) (conv3)\n",
    "    \n",
    "    conv4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (pool3)\n",
    "    conv4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2)) (conv4)\n",
    "\n",
    "\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (pool4)\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (conv5)\n",
    "    \n",
    "    \n",
    "    up6 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (conv5)\n",
    "    up6 = layers.concatenate([up6, conv4])\n",
    "    conv6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (up6)\n",
    "    conv6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (conv6)\n",
    "    up7 = layers.concatenate([up7, conv3])\n",
    "    conv7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (up7)\n",
    "    conv7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (conv7)\n",
    "    \n",
    "    up8 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (conv7)\n",
    "    up8 = layers.concatenate([up8, conv2])\n",
    "    conv8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (up8)\n",
    "    conv8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (conv8)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (conv8)\n",
    "    up9 = layers.concatenate([up9, conv1], axis=3)\n",
    "    conv9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (up9)\n",
    "    conv9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (conv9)\n",
    "\n",
    "    conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    \n",
    "    return models.Model([input_layer], [conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c5cf8bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_462 (Conv2D)            (None, 256, 256, 8)  224         ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_463 (Conv2D)            (None, 256, 256, 8)  584         ['conv2d_462[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_104 (MaxPooling2  (None, 128, 128, 8)  0          ['conv2d_463[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_464 (Conv2D)            (None, 128, 128, 16  1168        ['max_pooling2d_104[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_465 (Conv2D)            (None, 128, 128, 16  2320        ['conv2d_464[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_105 (MaxPooling2  (None, 64, 64, 16)  0           ['conv2d_465[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_466 (Conv2D)            (None, 64, 64, 32)   4640        ['max_pooling2d_105[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_467 (Conv2D)            (None, 64, 64, 32)   9248        ['conv2d_466[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_106 (MaxPooling2  (None, 32, 32, 32)  0           ['conv2d_467[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_468 (Conv2D)            (None, 32, 32, 64)   18496       ['max_pooling2d_106[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_469 (Conv2D)            (None, 32, 32, 64)   36928       ['conv2d_468[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_107 (MaxPooling2  (None, 16, 16, 64)  0           ['conv2d_469[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_470 (Conv2D)            (None, 16, 16, 128)  73856       ['max_pooling2d_107[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_471 (Conv2D)            (None, 16, 16, 128)  147584      ['conv2d_470[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 32, 32, 64)  32832       ['conv2d_471[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 32, 32, 128)  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                                                  'conv2d_469[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_472 (Conv2D)            (None, 32, 32, 64)   73792       ['concatenate_91[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_473 (Conv2D)            (None, 32, 32, 64)   36928       ['conv2d_472[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 64, 64, 32)  8224        ['conv2d_473[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_92 (Concatenate)   (None, 64, 64, 64)   0           ['conv2d_transpose_10[0][0]',    \n",
      "                                                                  'conv2d_467[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_474 (Conv2D)            (None, 64, 64, 32)   18464       ['concatenate_92[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_475 (Conv2D)            (None, 64, 64, 32)   9248        ['conv2d_474[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 128, 128, 16  2064       ['conv2d_475[0][0]']             \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_93 (Concatenate)   (None, 128, 128, 32  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                )                                 'conv2d_465[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_476 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_93[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_477 (Conv2D)            (None, 128, 128, 16  2320        ['conv2d_476[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 256, 256, 8)  520        ['conv2d_477[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 256, 256, 16  0           ['conv2d_transpose_12[0][0]',    \n",
      "                                )                                 'conv2d_463[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_478 (Conv2D)            (None, 256, 256, 8)  1160        ['concatenate_94[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_479 (Conv2D)            (None, 256, 256, 8)  584         ['conv2d_478[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_480 (Conv2D)            (None, 256, 256, 1)  9           ['conv2d_479[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 485,817\n",
      "Trainable params: 485,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1f0286fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3 * binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "591b90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5',\n",
    "    monitor = 'val_dice_coeff',\n",
    "    verbose=1,\n",
    "    save_best_only = True,\n",
    "    mode = 'max',\n",
    "    save_weights_only = True\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor = 'val_dice_coef',\n",
    "    factor = 0.5,\n",
    "    patience = 3, \n",
    "    mode = 'max', \n",
    "    cooldown = 2, \n",
    "    min_lr = 1e-6\n",
    ")\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor = \"val_dice_coef\",\n",
    "    mode = \"max\",\n",
    "    patience = 15\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early, reduce_lr_on_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6803ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    model.compile(optimizer = Adam(lr = 1e-4, decay=1e-6), loss = dice_p_bce, metrics = [dice_coef])\n",
    "    \n",
    "    step_count = min(MAX_TRAIN_STEPS, train_df.shape[0]//BATCH_SIZE)\n",
    "    \n",
    "    aug_gen = augmented_generator(data_generator(train_df))\n",
    "    \n",
    "    loss_history = [model.fit_generator(aug_gen,\n",
    "                                 steps_per_epoch=step_count,\n",
    "                                 epochs=N_EPOCHS,\n",
    "                                 validation_data=(val_x, val_y),\n",
    "                                 callbacks=callbacks,\n",
    "                                 workers=1)] \n",
    "    return loss_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c0a76b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 0s - loss: -0.0186 - dice_coef: 0.0194"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ZenBook\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ZenBook\\AppData\\Local\\Temp\\ipykernel_15000\\3861438825.py\", line 11, in dice_p_bce  *\n        return 1e-3 * binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n    File \"C:\\Users\\ZenBook\\AppData\\Local\\Temp\\ipykernel_15000\\3861438825.py\", line 6, in dice_coef  *\n        intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int16 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [344]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [343]\u001b[0m, in \u001b[0;36mfit\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m step_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(MAX_TRAIN_STEPS, train_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE)\n\u001b[0;32m      6\u001b[0m aug_gen \u001b[38;5;241m=\u001b[39m augmented_generator(data_generator(train_df))\n\u001b[1;32m----> 8\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43maug_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m] \n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_history\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2624\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2625\u001b[0m \n\u001b[0;32m   2626\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2627\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2630\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2634\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2635\u001b[0m )\n\u001b[1;32m-> 2636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2638\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2648\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebyaf5ho1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7m9nc5bb.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dice_p_bce\u001b[1;34m(in_gt, in_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(binary_crossentropy), (ag__\u001b[38;5;241m.\u001b[39mld(in_gt), ag__\u001b[38;5;241m.\u001b[39mld(in_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(dice_coef), (ag__\u001b[38;5;241m.\u001b[39mld(in_gt), ag__\u001b[38;5;241m.\u001b[39mld(in_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filed49n5k5m.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dice_coef\u001b[1;34m(y_true, y_pred, smooth)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m intersection \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39msum, (ag__\u001b[38;5;241m.\u001b[39mld(y_true) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), fscope)\n\u001b[0;32m     11\u001b[0m union \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39msum, (ag__\u001b[38;5;241m.\u001b[39mld(y_true),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39msum, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), fscope)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ZenBook\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ZenBook\\AppData\\Local\\Temp\\ipykernel_15000\\3861438825.py\", line 11, in dice_p_bce  *\n        return 1e-3 * binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n    File \"C:\\Users\\ZenBook\\AppData\\Local\\Temp\\ipykernel_15000\\3861438825.py\", line 6, in dice_coef  *\n        intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int16 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    loss_history = fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rle, image_id = [], []\n",
    "for i in train:\n",
    "    image = cv2.imread(TEST_DIRT_DIRST_DIR + i).reshape(1, 256, 256, 3)  # ?????\n",
    "    pred = model.predict(image).reshape(256, 256)             # ?????\n",
    "    image_id.append(file.split('/')[-1][:-4])\n",
    "    encoding = mask_to_rle(pred, 256, 256)\n",
    "    if encoding == ' ':\n",
    "        rle.append('-1')\n",
    "    else:\n",
    "        rle.append(encoding)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c45b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
